# Crawling 

> 13ê¸° ì¡°ìƒì—°

## ì¤€ë¹„


```python
!pip install requests bs4 selenium pandas
```

    Requirement already satisfied: requests in /Users/josang-yeon/tobigs/lib/python3.7/site-packages (2.22.0)
    Requirement already satisfied: bs4 in /Users/josang-yeon/tobigs/lib/python3.7/site-packages (0.0.1)
    Requirement already satisfied: selenium in /Users/josang-yeon/tobigs/lib/python3.7/site-packages (3.141.0)
    Requirement already satisfied: pandas in /Users/josang-yeon/tobigs/lib/python3.7/site-packages (1.0.0rc0)
    Requirement already satisfied: certifi>=2017.4.17 in /Users/josang-yeon/tobigs/lib/python3.7/site-packages (from requests) (2019.11.28)
    Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/josang-yeon/tobigs/lib/python3.7/site-packages (from requests) (3.0.4)
    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/josang-yeon/tobigs/lib/python3.7/site-packages (from requests) (1.25.7)
    Requirement already satisfied: idna<2.9,>=2.5 in /Users/josang-yeon/tobigs/lib/python3.7/site-packages (from requests) (2.8)
    Requirement already satisfied: beautifulsoup4 in /Users/josang-yeon/tobigs/lib/python3.7/site-packages (from bs4) (4.6.0)
    Requirement already satisfied: pytz>=2017.2 in /Users/josang-yeon/tobigs/lib/python3.7/site-packages (from pandas) (2019.3)
    Requirement already satisfied: numpy>=1.13.3 in /Users/josang-yeon/tobigs/lib/python3.7/site-packages (from pandas) (1.18.1)
    Requirement already satisfied: python-dateutil>=2.6.1 in /Users/josang-yeon/tobigs/lib/python3.7/site-packages (from pandas) (2.8.1)
    Requirement already satisfied: six>=1.5 in /Users/josang-yeon/tobigs/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.13.0)
    [33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.
    You should consider upgrading via the '/Users/josang-yeon/tobigs/bin/python -m pip install --upgrade pip' command.[0m



```python
import requests
import pandas as pd
```

## 0. ê¸°ì´ˆ

### 0.1. ê¸°ë³¸ì ì¸ ì›¹ í†µì‹  ì´í•´í•˜ê¸°

> ê°•ì˜ ìë£Œ ì°¸ê³ 

### 0.2. HTML ë¬¸ì„œ ì´í•´í•˜ê¸°


```python
from IPython import display
```


```python
display.HTML("""
<style>
div > p { color: black }
#hi { color: blue }
.green { color: green }
[value="3"] { color: grey }
</style>
<div>
    <h5>Hello, world!</h5>
    <p class="green">ì•ˆë…•í•˜ì„¸ìš”</p>
    <p>ì•ˆë…•í•˜ì„¸ìš”</p>
    <p id="hi">ì•ˆë…•í•˜ì„¸ìš”</p>
    <p class="green">ì•ˆë…•í•˜ì„¸ìš”</p>
    <p value="3">ì•ˆë…•í•˜ì„¸ìš”</p>
</div>
""")
```





<style>
div > p { color: black }
#hi { color: blue }
.green { color: green }
[value="3"] { color: grey }
</style>
<div>
    <h5>Hello, world!</h5>
    <p class="green">ì•ˆë…•í•˜ì„¸ìš”</p>
    <p>ì•ˆë…•í•˜ì„¸ìš”</p>
    <p id="hi">ì•ˆë…•í•˜ì„¸ìš”</p>
    <p class="green">ì•ˆë…•í•˜ì„¸ìš”</p>
    <p value="3">ì•ˆë…•í•˜ì„¸ìš”</p>
</div>




### 0.3. Requests í™œìš© ê¸°ë³¸ í¬ë¡¤ë§

1. Method í™•ì¸
2. í•„ìš”í•œ ë¶€í’ˆ (URL, Params, Header, Data) ì²´í¬
3. ê²°ê³¼ í™•ì¸ ë° ì˜¤ë¥˜ ì‹œ 2ë²ˆ ì‚¬í•­ ë°˜ë³µ ì²´í¬
4. ê²°ê³¼ í˜•ì‹ì— ë”°ë¼ íŒŒì‹±

#### 0.3.1. GET ë°©ì‹


```python
res = requests.get("https://search.naver.com/search.naver?where=news&sm=tab_jum&query=í…Œë„·")
res
```




    <Response [200]>




```python
res.text[:500]
```




    '<!doctype html> <html lang="ko"> <head> <meta charset="utf-8"> <meta name="referrer" content="always">  <meta name="format-detection" content="telephone=no,address=no,email=no"> <meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=2.0"> <meta property="og:title" content="í…Œë„· : ë„¤ì´ë²„ ë‰´ìŠ¤ê²€ìƒ‰"/> <meta property="og:image" content="https://ssl.pstatic.net/sstatic/search/common/og_v3.png"> <meta property="og:description" content="\'í…Œë„·\'ì˜ ë„¤ì´ë²„ ë‰´ìŠ¤ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤."> <meta name="description"'



ê¸°ë³¸ì ìœ¼ë¡œ URLì— Paramsë¥¼ ë„£ì–´ë„ ë™ì‘í•˜ì§€ë§Œ ë” ë‚˜ì€ ë°©ì‹ì„ ìœ„í•´ ì•„ë˜ì™€ ê°™ì´ í™œìš©í•´ë³´ì!


```python
# URL
def get_news_search_result(keword):
    url = "https://search.naver.com/search.naver"
    
    # Parameter -> Queryê°€ ë¨ https://search.naver.com/search.naver?where=news&sm=tab_jum&query=í…Œë„·
    my_params = {'where': 'news', 
              'sm': 'tab_jum', 
              'query': keword}

    # Headers ì„¤ì •
    my_headers = {
        "referer": "https://www.tobigs.com"
    }

    # ì „ì†¡
    res = requests.get(url, params=my_params, headers=my_headers)
    return res # ìƒíƒœì½”ë“œ 200ìœ¼ë¡œ ì„±ê³µ
```


```python
res.text[:500] # ê²°ê³¼
```




    '<!doctype html> <html lang="ko"> <head> <meta charset="utf-8"> <meta name="referrer" content="always">  <meta name="format-detection" content="telephone=no,address=no,email=no"> <meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=2.0"> <meta property="og:title" content="í…Œë„· : ë„¤ì´ë²„ ë‰´ìŠ¤ê²€ìƒ‰"/> <meta property="og:image" content="https://ssl.pstatic.net/sstatic/search/common/og_v3.png"> <meta property="og:description" content="\'í…Œë„·\'ì˜ ë„¤ì´ë²„ ë‰´ìŠ¤ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤."> <meta name="description"'



#### 0.3.2. POST ë°©ì‹


```python
url = "https://api.everytime.kr/find/lecture/article/list"
```


```python
import requests

url = "https://api.everytime.kr/find/lecture/article/list"

payload = {
    'school_id': 9, 
    'limit_num':200,
    'lecture_id': 1688764}

headers = {
  'Cookie': '_ga=GA1.2.168813388.1596099998; _gid=GA1.2.1403299065.1597760084; _gat_gtag_UA_22022140_4=1; etsid=',
  'Content-Type': 'application/x-www-form-urlencoded'}

response = requests.post(url, headers=headers, data = payload)
```


```python
print(response.text[:500])
```

    <?xml version="1.0" encoding="UTF-8"?>
    <response lectureId="1688764">
      <lecture name="ì»´í“¨í„°ë„¤íŠ¸ì›ê°œë¡ " professor="ê¹€ìœ ì„±" campus=""/>
      <rate>4.55</rate>
      <details assessment_grade="í•™ì ëŠë‹˜" assessment_homework="ë³´í†µ" assessment_team="ì—†ìŒ" assessment_attendance="ì „ìì¶œê²°" exam_times="ë‘ ë²ˆ"/>
      <semesters>
        <semester year="2020" semester="2"/>
        <semester year="2020" semester="1"/>
        <semester year="2019" semester="2"/>
        <semester year="2018" semester="2"/>
        <semester year="2018" semester="1"/>
        <se


## 1. ì´ˆê¸‰

### 1.0. JSON í˜•ì‹


```python
import json
```


```python
url = "https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2020_0__24cc3874b05eea134ee2716dbf93f11a.json"
headers = {
    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.125 Safari/537.36',
    'cookie': 'geoCountry=KR; siteCountry=GB; has_js=1; Drupal.visitor.the_user=%7B%22show_menu%22%3A0%2C%22user_closed%22%3A0%7D; __tesu=6765b049-1b8b-4cec-bc92-de35818b600d; _ga=GA1.2.1649170199.1597508290; _fbp=fb.1.1597508290544.2090481780; __gads=ID=92b9981fb38f9252'
}
response = requests.get(url, headers=headers)
result = response.json()

response

df_univ_ranking = pd.json_normalize(result["data"])
```


```python
df_univ_ranking.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rank_order</th>
      <th>rank</th>
      <th>name</th>
      <th>scores_overall</th>
      <th>scores_overall_rank</th>
      <th>scores_teaching</th>
      <th>scores_teaching_rank</th>
      <th>scores_research</th>
      <th>scores_research_rank</th>
      <th>scores_citations</th>
      <th>...</th>
      <th>url</th>
      <th>nid</th>
      <th>location</th>
      <th>stats_number_students</th>
      <th>stats_student_staff_ratio</th>
      <th>stats_pc_intl_students</th>
      <th>stats_female_male_ratio</th>
      <th>aliases</th>
      <th>subjects_offered</th>
      <th>apply_link</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10</td>
      <td>1</td>
      <td>University of Oxford</td>
      <td>95.4</td>
      <td>10</td>
      <td>90.5</td>
      <td>6</td>
      <td>99.6</td>
      <td>1</td>
      <td>98.4</td>
      <td>...</td>
      <td>/world-university-rankings/university-oxford</td>
      <td>468</td>
      <td>United Kingdom</td>
      <td>20,664</td>
      <td>11.2</td>
      <td>41%</td>
      <td>46 : 54</td>
      <td>ç‰›æ´¥å¤§å­¦</td>
      <td>Mechanical &amp; Aerospace Engineering,Computer Sc...</td>
      <td>https://www.timeshighereducation.com/cn/studen...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>20</td>
      <td>2</td>
      <td>California Institute of Technology</td>
      <td>94.5</td>
      <td>20</td>
      <td>92.1</td>
      <td>2</td>
      <td>97.2</td>
      <td>4</td>
      <td>97.9</td>
      <td>...</td>
      <td>/world-university-rankings/california-institut...</td>
      <td>128779</td>
      <td>United States</td>
      <td>2,240</td>
      <td>6.4</td>
      <td>30%</td>
      <td>34 : 66</td>
      <td>California Institute of Technology caltech</td>
      <td>Biological Sciences,Mechanical &amp; Aerospace Eng...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>30</td>
      <td>3</td>
      <td>University of Cambridge</td>
      <td>94.4</td>
      <td>30</td>
      <td>91.4</td>
      <td>4</td>
      <td>98.7</td>
      <td>2</td>
      <td>95.8</td>
      <td>...</td>
      <td>/world-university-rankings/university-cambridge</td>
      <td>470</td>
      <td>United Kingdom</td>
      <td>18,978</td>
      <td>10.9</td>
      <td>37%</td>
      <td>47 : 53</td>
      <td>å‰‘æ¡¥å¤§å­¦</td>
      <td>Languages, Literature &amp; Linguistics,Computer S...</td>
      <td>https://www.timeshighereducation.com/cn/studen...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>40</td>
      <td>4</td>
      <td>Stanford University</td>
      <td>94.3</td>
      <td>40</td>
      <td>92.8</td>
      <td>1</td>
      <td>96.4</td>
      <td>5</td>
      <td>99.9</td>
      <td>...</td>
      <td>/world-university-rankings/stanford-university</td>
      <td>467</td>
      <td>United States</td>
      <td>16,135</td>
      <td>7.3</td>
      <td>23%</td>
      <td>43 : 57</td>
      <td>Stanford University</td>
      <td>Archaeology,Physics &amp; Astronomy,Law,General En...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>50</td>
      <td>5</td>
      <td>Massachusetts Institute of Technology</td>
      <td>93.6</td>
      <td>50</td>
      <td>90.5</td>
      <td>5</td>
      <td>92.4</td>
      <td>10</td>
      <td>99.5</td>
      <td>...</td>
      <td>/world-university-rankings/massachusetts-insti...</td>
      <td>471</td>
      <td>United States</td>
      <td>11,247</td>
      <td>8.6</td>
      <td>34%</td>
      <td>39 : 61</td>
      <td>Massachusetts Institute of Technology</td>
      <td>Veterinary Science,Languages, Literature &amp; Lin...</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows Ã— 27 columns</p>
</div>




```python
# df_univ_ranking.to_json("univ_rank_2020.json")
# df_univ_ranking.to_json("univ_rank_2020.json",orient="records")
```

### 1.1. BeautifulSoupë¥¼ ì´ìš©í•œ HTML íŒŒì‹±


```python
from bs4 import BeautifulSoup
```


```python
res = get_news_search_result("ì½”ë¡œë‚˜")
if res.status_code == 200: print("OK!")
```

    OK!



```python
soup = BeautifulSoup(res.text, "html.parser")
```


```python
[
    dl.select("a._sp_each_title")[0]["title"].strip()
    for dl 
    in soup.select("dl")[2:-1]
]
```




    ["'ê´‘í™”ë¬¸ ì§‘íšŒ ì°¸ì„' ì°¨ëª…ì§„ ì „ ì˜ì› ì½”ë¡œë‚˜19 í™•ì§„(ì¢…í•©)",
     "ì´ë‚™ì—°, ì½”ë¡œë‚˜19 ê²€ì‚¬ 'ìŒì„±'â€¦ì¼ì • ì¬ê°œëŠ” ë¯¸ì •(ì¢…í•©)",
     'í•´ì™¸ìœ ì… ì½”ë¡œë‚˜í™•ì§„ì ì˜ˆì¸¡í•˜ëŠ” AI ë‚˜ì™”ë‹¤',
     "'ê´‘í™”ë¬¸ ì§‘íšŒ ì°¸ì„' ì°¨ëª…ì§„ ì „ ì˜ì› ì½”ë¡œë‚˜19 í™•ì§„",
     'ì´ë‚™ì—°, ì½”ë¡œë‚˜19 \'ìŒì„±\' íŒì •â€¦"ëª¨ë‘ë¥¼ ìœ„í•´ ë‹¤í–‰"(ì¢…í•©)',
     'ë‚˜í›ˆì•„, 20ì¼ ì‹ ê³¡ ë°œí‘œ "ì½”ë¡œë‚˜ë¡œ ì‚­ë§‰í•œ ì„¸ìƒ...í•´í•™ ë‹´ì•„" [ê³µì‹]',
     "[ë‹¨ë…] ì² ì› ì‹ ë³‘êµìœ¡ëŒ€ì—ì„œ ì½”ë¡œë‚˜ 'ì–‘ì„±' ë‚˜ì™€",
     'ì½”ë¡œë‚˜19 ì „êµ­ í™•ì‚°ì— â€œí•´ìˆ˜ìš•ì¥ ì´ìš© ìì œâ€',
     "ì´ë‚™ì—°, ì½”ë¡œë‚˜19 'ìŒì„±'â€¦ì •ì¹˜ê¶Œ ì•ˆë„(ì¢…í•©)",
     'ë™í™”ì•½í’ˆ, ì½”ë¡œë‚˜19 ì¹˜ë£Œì œ ì„ìƒ2ìƒ ì‹œí—˜ ì‹ ì²­']



### 1.2. ì…€ë ˆë‹ˆì›€ í™œìš© í¬ë¡¤ë§

**ì…€ë ˆë‹ˆì›€ ì´ë€**

- ì›ë˜ ì›¹ í…ŒìŠ¤íŒ… ìš©ë„ë¡œ ê°œë°œ
- ê·¸ëŸ¬ë‹¤ë³´ë‹ˆ ì›¹ì—ì„œ í•˜ëŠ” ëª¨ë“  í–‰ìœ„ë¥¼ ë‹¤ í•  ìˆ˜ ìˆìŒ
- ì´ëŸ¬í•œ ê¸°ëŠ¥ì„ í†µí•´ í¬ë¡¤ë§ì´ í˜ë“¤ê±°ë‚˜ ì–´ë ¤ìš´ ì‚¬ì´íŠ¸ë¥¼ ë…¸ê°€ë‹¤ë¥¼ í†µí•´ í¬ë¡¤ë§ í•  ìˆ˜ ìˆê²Œí•¨

**ì…€ë ˆë‹ˆì›€ ë™ì‘ ìˆœì„œ**

1. driver íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ ë°›ê³  ë…¸íŠ¸ë¶ íŒŒì¼ê³¼ ê°™ì€ ìœ„ì¹˜ì— ë„£ì–´ì¤€ë‹¤.
2. `driver = webdriver.Chrome(ë“œë¼ì´ë²„ ê²½ë¡œ)`ë¥¼ í†µí•´ ë“œë¼ì´ë²„ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤.
    2.1. ì´ë•Œ ì•ˆë³´ì´ê²Œ í•˜ê³  ì‹¶ë‹¤ë©´ headless ì˜µì…˜ì„ ì´ìš©í•œë‹¤.
3. í•´ë‹¹ ë“œë¼ì´ë²„ê°€ ì¼œì§„ ê²ƒì„ í™•ì¸
4. `driver.get(URL)`ì„ ì´ìš©í•´ ì›í•˜ëŠ” í˜ì´ì§€ë¡œ ì´ë™í•œë‹¤.
5. `driver.find_element[s]_by_css_selector` ë¥¼ ì´ìš©í•˜ì—¬ ì›í•˜ëŠ” ë¶€ë¶„ì„ ì°¾ëŠ”ë‹¤.

    5.0. ì°¾ì€ ê²°ê³¼ëŠ” elementì´ë©° element.textë¥¼ í†µí•´ ì•ˆ ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤.
    
    5.1. `element.send_keys(ì›í•˜ëŠ” ë‚´ìš©,ID,PW)`ì„ í†µí•´ ê°’ì„ ì…ë ¥í•  ìˆ˜ ìˆë‹¤.
    
    5.2. `element.click()`ì„ í†µí•´ ë²„íŠ¼ ë“±ì„ í´ë¦­í•  ìˆ˜ ìˆë‹¤.
    
6. `driver.page_source`ë¥¼ í†µí•´ ì „ì²´ í˜ì´ì§€ ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤.

    6.1. ë§Œì•½ ì†ŒìŠ¤ì— ë‚´ê°€ ì›í•˜ëŠ” ë‚´ìš©ì´ ì—†ë‹¤ë©´ iframeì— ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆë‹¤.
    
    6.2. ì´ëŸ¬í•œ ê²½ìš° `driver.switch_to.frame(í•´ë‹¹ ifram element)`ë¡œ ì´ë™í•œë‹¤.
    
    6.3. Alert, ë‹¤ë¥¸ ì°½ìœ¼ë¡œ ì—´ê¸° ë“± ë‹¤ì–‘í•œ ë³€ìˆ˜ì— ëŒ€í•´ì„œë„ `driver.switch_to`ë¡œ ëŒ€ì‘ì´ ê°€ëŠ¥
    
7. `driver.close()`ë¡œ í•´ë‹¹ ë“œë¼ì´ë²„ë¥¼ ì¢…ë£Œí•œë‹¤.




```python
from selenium import webdriver
from IPython.display import Image
import os
from pathlib import Path
import glob
```

#### 1.2.0. ì´ë¯¸ì§€ ë³´ê¸° ê¿€íŒ


```python
python_image_url = "https://www.python.org/static/img/python-logo.png"
Image(python_image_url)
```




![png](output_37_0.png)



#### 1.2.1. ì…€ë ˆë‹ˆì›€ ê¸°ë³¸ ì‹¤í–‰


```python
print(f"Directory Path: {Path().absolute()}") 
```

    Directory Path: /Users/josang-yeon/Downloads/week4_Ensemble_yjlee



```python
glob.glob("chrome*") # í˜„ì¬ í´ë” ë‚´ í¬ë¡¬ ë“œë¼ì´ë²„ ëª… í™•ì¸
```




    ['chromedriver_win.exe', 'chromedriver_linux', 'chromedriver_mac']




```python
driver_path = os.path.join(Path().absolute(),  "chromedriver_mac") # ë³¸ì¸ ìš´ì˜ì²´ì œì— ë§ê²Œ ë°”ê¿”ì¤˜ì•¼í•¨
```


```python
driver = webdriver.Chrome(driver_path)
driver.get("https://www.naver.com")
```


```python
driver.quit()
```

#### 1.2.2. Headless ì˜µì…˜ ì£¼ê¸°


```python
from selenium.webdriver.chrome.options import Options

options = Options()
options.headless = True # Trueë©´ ì°½ì´ ì•ˆëœ¸
driver = webdriver.Chrome(driver_path, options=options)
```


```python
# driver.set_window_size(1920, 1080)
```


```python
# Image(driver.get_screenshot_as_png())
```


```python
# driver.quit()
# options.headless = False # Trueë©´ ì°½ì´ ì•ˆëœ¸
# driver = webdriver.Chrome(driver_path, options=options)

driver.get("https://www.coupang.com/np/search?q=%EB%8B%8C%ED%85%90%EB%8F%84%20%EC%8A%A4%EC%9C%84%EC%B9%98&channel=recent")
```


```python
Image(driver.get_screenshot_as_png())
```


```python
driver.execute_script("return navigator.userAgent")
```


```python
[
    [element.find_element_by_css_selector("div.name").text, element.find_element_by_css_selector("strong.price-value").text]
    for element 
    in driver.find_elements_by_css_selector(".search-product-link")
][:5]
```




    [['í˜¸í™˜ìš© ë‹Œí…ë„ìŠ¤ìœ„ì¹˜ í”„ë¡œì»¨íŠ¸ë¡¤ëŸ¬ í”„ë¡œì»¨ í”„ë¡œì½˜, 1ê°œ, 8ë²ˆ IINEì •í’ˆí•‘í¬ìº£', '51,900'],
     ['ì •í’ˆ ë‹Œí…ë„ ìŠ¤ìœ„ì¹˜ ë³¸ì²´ ë°°í„°ë¦¬ ê°œì„ íŒ, ë°°í„°ë¦¬ ê°œì„ íŒ ë„¤ì˜¨', '487,500'],
     ['ë‹Œí…ë„ìŠ¤ìœ„ì¹˜ë¼ì´íŠ¸ ë³¸ì²´ í„°ì½°ì´ì¦ˆ + ìŠ¤íƒ€í„°í‚· ì•¡ì„¸ì„œë¦¬ 6ì¢… ì„¸íŠ¸, HDH-001', '269,000'],
     ['ë‹Œí…ë„ ìŠ¤ìœ„ì¹˜ ë™ë¬¼ì˜ìˆ² ì—ë””ì…˜ í•œê¸€ ë™ë¬¼ì˜ ìˆ² ë°°í„°ë¦¬ê°œì„ íŒ ì‹ í’ˆ, ë‹Œí…ë„ ìŠ¤ìœ„ì¹˜ HAD ì‹ í˜• ë™ë¬¼ì˜ìˆ² ì—ë””ì…˜ í•œê¸€ ë™ë¬¼ì˜ ìˆ² ì—ë””ì…˜ ìƒˆì œí’ˆ',
      '535,000'],
     ['ìµ¸ë¯¸ì•¤ì„¸ë¸ ë‹Œí…ë„ ìŠ¤ìœ„ì¹˜ ìŠ¤íƒ€í„° ì•…ì„¸ì„œë¦¬ íŒ¨í‚¤ì§€ 4ì¢… Dì„¸íŠ¸, ë‹¨ì¼ ìƒí’ˆ, 1ì„¸íŠ¸', '13,500']]



> BeautifulSoupë¥¼ ì´ìš©í•œ ë‹¤ë¥¸ ë°©ë²•


```python
soup = BeautifulSoup(driver.page_source, "html.parser")
```


```python
[
    element.text.strip()
    for element in soup.select(".search-product-link")
][:5]
```




    ['ê´‘ê³    |  ë¬´ë£Œë°°ì†¡ í˜¸í™˜ìš© ë‹Œí…ë„ìŠ¤ìœ„ì¹˜ í”„ë¡œì»¨íŠ¸ë¡¤ëŸ¬ í”„ë¡œì»¨ í”„ë¡œì½˜, 1ê°œ, 8ë²ˆ IINEì •í’ˆí•‘í¬ìº£  \n \n51,900ì›     \n 8/27   ë„ì°© ì˜ˆì •   \n5.0 (10)  ìµœëŒ€ 2,595ì› ì ë¦½',
     'ë¬´ë£Œë°°ì†¡ ì •í’ˆ ë‹Œí…ë„ ìŠ¤ìœ„ì¹˜ ë³¸ì²´ ë°°í„°ë¦¬ ê°œì„ íŒ, ë°°í„°ë¦¬ ê°œì„ íŒ ë„¤ì˜¨  \n \n487,500ì›     \n ëª¨ë ˆ(ê¸ˆ) 8/21   ë„ì°© ì˜ˆì •   \n5.0 (38)  ìµœëŒ€ 24,375ì› ì ë¦½ 1',
     'ë‹Œí…ë„ìŠ¤ìœ„ì¹˜ë¼ì´íŠ¸ ë³¸ì²´ í„°ì½°ì´ì¦ˆ + ìŠ¤íƒ€í„°í‚· ì•¡ì„¸ì„œë¦¬ 6ì¢… ì„¸íŠ¸, HDH-001  \n \n269,000ì›  \n         \n  \n ë‚´ì¼(ëª©) 8/20   ë„ì°© ë³´ì¥  \n    ë‚´ì¼(ëª©) ìƒˆë²½   ë„ì°© ë³´ì¥  \n \n5.0 (44)  ìµœëŒ€ 13,450ì› ì ë¦½ 2',
     'ë‹Œí…ë„ ìŠ¤ìœ„ì¹˜ ë™ë¬¼ì˜ìˆ² ì—ë””ì…˜ í•œê¸€ ë™ë¬¼ì˜ ìˆ² ë°°í„°ë¦¬ê°œì„ íŒ ì‹ í’ˆ, ë‹Œí…ë„ ìŠ¤ìœ„ì¹˜ HAD ì‹ í˜• ë™ë¬¼ì˜ìˆ² ì—ë””ì…˜ í•œê¸€ ë™ë¬¼ì˜ ìˆ² ì—ë””ì…˜ ìƒˆì œí’ˆ  \n \n535,000ì›     \n ëª¨ë ˆ(ê¸ˆ) 8/21   ë„ì°© ì˜ˆì •   \n5.0 (39)  ìµœëŒ€ 26,750ì› ì ë¦½ 3',
     'ê´‘ê³     ìµ¸ë¯¸ì•¤ì„¸ë¸ ë‹Œí…ë„ ìŠ¤ìœ„ì¹˜ ìŠ¤íƒ€í„° ì•…ì„¸ì„œë¦¬ íŒ¨í‚¤ì§€ 4ì¢… Dì„¸íŠ¸, ë‹¨ì¼ ìƒí’ˆ, 1ì„¸íŠ¸  \n \n13,500ì›  \n         \n  \n ë‚´ì¼(ëª©) 8/20   ë„ì°© ë³´ì¥  \n    ë‚´ì¼(ëª©) ìƒˆë²½   ë„ì°© ë³´ì¥  \n \n4.5 (98)  ìµœëŒ€ 675ì› ì ë¦½']



#### 1.2.3. ì‹¤ì „! ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ë¡¤ë§


```python
driver.get("https://www.instagram.com/explore/tags/ê³ ì–‘ì´ìŠ¤íƒ€ê·¸ë¨")
```


```python
# Image(driver.get_screenshot_as_png(), width=500)
```


```python
MAX_HEIGHT = 2000000
driver.execute_script(f"window.scrollTo(0,{MAX_HEIGHT})")
```


```python
Image(driver.get_screenshot_as_png(), width=500)
```




![png](output_59_0.png)




```python
len(elements)
```




    45




```python
soup = BeautifulSoup(driver.page_source,"html.parser")
elements = soup.select("div.v1Nh3.kIKUG._bz0w")
```


```python
len(elements)
```




    45




```python
driver.find_element_by_css_selector('input[name="username"]').send_keys("myId")
driver.find_element_by_css_selector('input[name="password"]').send_keys("mypassword")
driver.find_element_by_css_selector('button[type="submit"]').click()
```


```python
driver.close()
```

## 2. ì¤‘ê¸‰

### 2.1. ë™ì  ì›¹ì‚¬ì´íŠ¸ XHR í¬ë¡¤ë§


```python
res = requests.get("https://www.instagram.com/explore/tags/%EA%B3%A0%EC%96%91%EC%9D%B4%EC%8A%A4%ED%83%80%EA%B7%B8%EB%9E%A8/?__a=1")
```


```python
def find_by_path(path, target_json):
    path_arr = path.split(".")
    while path_arr:
        target_json = target_json.get(path_arr.pop(0), {})
        
    if not target_json: raise Exception("í•´ë‹¹ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
    return target_json 
```


```python
a = response.json()
target_nodes = find_by_path("graphql.hashtag.edge_hashtag_to_media.edges", a)
top_nodes = find_by_path("graphql.hashtag.edge_hashtag_to_top_posts.edges", a)
END_CURSOR_PATH = "graphql.hashtag.edge_hashtag_to_media.page_info.end_cursor"
```


```python
end_cursor = find_by_path(END_CURSOR_PATH, a)
```


```python
end_cursor
```




    'QVFCZFJBUkNPSklTbjBOWEVIWkM0c042ZGgxcC1XTkVsZjR2VXFibHk0ZExzeVhUM1VIVzlqMzgwSGZIUzNmaG5WbDZ1YWN0X2h1U0VXczk5ZlltZ21QZg=='




```python
url = "https://www.instagram.com/graphql/query/?query_hash=c769cb6c71b24c8a86590b22402fda50&variables={\"tag_name\":\"ê³ ì–‘ì´ìŠ¤íƒ€ê·¸ë¨\",\"first\":12,\"after\":\""+end_cursor+"\"}"
payload = {}
headers = {
  'Cookie': 'ig_did=656729E2-6F50-459C-982B-FB916EE97A25; csrftoken=hpAOmbp8QMG0cbqK4gLyZfpElSQ3XoRZ; rur=ASH; mid=XzwTTgAEAAEDAPtxIV4NSHR9nuPQ; urlgen="{\\"59.6.24.240\\": 4766}:1k85f1:yjpBnLz3E2eAs58BSNlDtdmt284"'
}

response = requests.request("GET", url, headers=headers, data = payload)
```


```python
response
```




    <Response [200]>




```python
# response.json()
```


```python
# pd.json_normalize(top_nodes)
```

### 2.2. GraphQL í¬ë¡¤ë§

ì‚¬ì‹¤ 2.1. ì´ GraphQLì´ë‹¤. ì´ê±´ íŒ¨ìŠ¤

### 2.3. ë¹ ë¥¸ ì†ë„ë¥¼ ìœ„í•œ ë©€í‹°í”„ë¡œì„¸ì‹± & ë©€í‹°ì“°ë ˆë”© í¬ë¡¤ë§


```python
driver.get("https://finance.naver.com/marketindex/exchangeDetail.nhn?marketindexCd=FX_USDKRW")
soup = BeautifulSoup(driver.page_source, "html.parser")
driver.switch_to.frame(driver.find_element_by_css_selector("iframe[title='ê³ ì‹œíšŒì°¨ë³„ ì‹œì„¸']"))

# Image(driver.get_screenshot_as_png())
soup = BeautifulSoup(driver.page_source, "html.parser")
soup.select("body > div > table")[0].select("td")[0].text
```


```python
import concurrent.futures
from multiprocessing import Pool
```


```python
from time import time
import functools

def timer(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start = time()
        ret = func(*args, **kwargs)
        print(f"ì‹¤í–‰ì‹œê°„: {time()-start:0.5f}ì´ˆ")
        return ret
    return wrapper
```


```python
def get_ex_usd_by_page(n):
    try:
        return pd.read_html(f"https://finance.naver.com/marketindex/exchangeDailyQuote.nhn?marketindexCd=FX_USDKRW&page={n}")[0]
    except:
        print("error")
    
@timer
def get_all_usd_single(N):
    return pd.concat([get_ex_usd_by_page(i) for i in range(1,N)])

@timer
def get_all_usd_by_multi_threads(N):
    nums = list(range(1,N))
    with concurrent.futures.ThreadPoolExecutor(max_workers=40) as executor:
        d = executor.map(get_ex_usd_by_page, nums)
    return pd.concat(d)

@timer
def get_all_usd_by_multi_processes(N):
    nums = list(range(1,N))
    pool = Pool(processes=2) # 2ê°œì˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    return pd.concat(pool.map(get_ex_usd_by_page, nums)) # get_contetn í•¨ìˆ˜ë¥¼ ë„£ì–´ì¤ì‹œë‹¤.
```


```python
df_1 = get_all_usd_single(50)
print(df_1.shape)

df_2 = get_all_usd_by_multi_threads(50)
print(df_2.shape)

df_3 = get_all_usd_by_multi_processes(50)
print(df_3.shape)
```

    ì‹¤í–‰ì‹œê°„: 7.45321ì´ˆ
    (490, 9)
    ì‹¤í–‰ì‹œê°„: 1.15378ì´ˆ
    (490, 9)
    ì‹¤í–‰ì‹œê°„: 4.33059ì´ˆ
    (490, 9)


## 3. ê³ ê¸‰

### 3.1. Session ì¸ì¦, ì•”í˜¸í™” í¬ë¡¤ë§

### 3.2. ì„œë²„ì‚¬ì´ë“œë Œë”ë§ í¬ë¡¤ë§

### 3.3. ë¦¬ë‹¤ì´ë ‰ì…˜ ë° Breakpoint í™œìš© í¬ë¡¤ë§

### 3.4. ìŠ¤ë§ˆíŠ¸í° ì•± ë°ì´í„° í¬ë¡¤ë§

## 4. ì‘ìš©

### 4.1. openGraph ì •ë³´ í™œìš©í•˜ê¸°

### 4.2. ê°„ë‹¨í•œ ìº¡ì±  ëš«ê¸°

### 4.3. Crontabì„ ì´ìš©í•œ í¬ë¡¤ë§ ìë™í™”

### 4.4. ì´ë¯¸ì§€, ë¹„ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë°›ê¸°

### 4.5. ë°ì´í„° ì €ì¥ ìµœì í™”
